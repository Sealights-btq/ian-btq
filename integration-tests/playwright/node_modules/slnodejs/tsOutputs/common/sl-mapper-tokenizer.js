"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.SlMapperTokenizer = void 0;
const files_utils_1 = require("./utils/files-utils");
/*
* This class is responsible for tokenizing the sl-mapping JSON object
* It provides both methods to tokenize and detokenize the JSON object
* The tokenized object is used to send the sl-mapping JSON object to the backend
* The detokenized object is used throughout the agent if a tokenized sl-mapping was received from the backend
*/
class SlMapperTokenizer {
    constructor() {
        this.SlMappingType = 'sl-mapping';
        this.version = 2;
        this.uniqueIdDelimiter = '@';
        this.pairDelimiter = '|';
        this.tokenDelimiter = '$';
    }
    isTokenizedSlMapping(slMapping) {
        return (slMapping === null || slMapping === void 0 ? void 0 : slMapping.type) === this.SlMappingType && slMapping.version === this.version;
    }
    tokenizeSlMapping(slMapping) {
        // Extract the common prefix for keys and values initially (projectRoot usually)
        const commonKeysPrefix = files_utils_1.FilesUtils.commonPathPrefix(Object.keys(slMapping));
        const commonValuesPrefix = files_utils_1.FilesUtils.commonPathPrefix(Object.values(slMapping));
        // Create tokens object to store the tokenized keys and values
        const tokens = {};
        const tokensMap = {};
        // Tokenize each key-value pair
        const tokenizedSlMapping = Object.entries(slMapping)
            .map(([key, value]) => this.tokenizeKeyValuePair(key, value, commonKeysPrefix, commonValuesPrefix, tokens, tokensMap)).join(this.pairDelimiter);
        return {
            type: this.SlMappingType,
            version: this.version,
            tokens,
            commonKeysPrefix,
            commonValuesPrefix,
            data: tokenizedSlMapping,
        };
    }
    detokenizeSlMapping(slMapping) {
        if (!this.isTokenizedSlMapping(slMapping)) {
            return slMapping;
        }
        const { tokens, data } = slMapping;
        const detokenizedSlMapping = data.split(this.pairDelimiter).reduce((acc, tokenizedKeyValuePair) => {
            const [keyToken, valueToken] = tokenizedKeyValuePair.split('=');
            const key = this.detokenizeToken(keyToken, slMapping.commonKeysPrefix, tokens);
            const value = this.detokenizeToken(valueToken, slMapping.commonValuesPrefix, tokens);
            acc[key] = value;
            return acc;
        }, {});
        return detokenizedSlMapping;
    }
    tokenizeKeyValuePair(key, value, commonKeysPrefix, commonValuesPrefix, tokens, tokensMap) {
        const keyParts = key.split(this.uniqueIdDelimiter);
        const valueParts = value.split(this.uniqueIdDelimiter);
        const keyToken = this.createToken(keyParts[0], commonKeysPrefix, tokens, tokensMap);
        const valueToken = this.createToken(valueParts[0], commonValuesPrefix, tokens, tokensMap);
        const keyPosition = keyParts[1];
        const valuePosition = valueParts[1];
        return `${keyToken}${this.uniqueIdDelimiter}${keyPosition}=${valueToken}${this.uniqueIdDelimiter}${valuePosition}`;
    }
    createToken(input, commonPrefix, tokens, tokensMap) {
        const inputWithoutPrefix = input.replace(commonPrefix, '');
        if (!tokensMap[inputWithoutPrefix]) {
            const tokenIndex = Object.keys(tokens).length;
            const token = `${this.tokenDelimiter}${tokenIndex}`;
            tokens[token] = inputWithoutPrefix.split(this.uniqueIdDelimiter)[0]; // Store token with its uncompressed value without the method position
            tokensMap[inputWithoutPrefix] = token;
        }
        return tokensMap[inputWithoutPrefix];
    }
    detokenizeToken(token, prefix, tokens) {
        const [tokenValue, position] = token.split(this.uniqueIdDelimiter);
        const originalSlMappingValue = tokens[tokenValue];
        return `${prefix}${originalSlMappingValue}${this.uniqueIdDelimiter}${position}`;
    }
}
exports.SlMapperTokenizer = SlMapperTokenizer;
//# sourceMappingURL=sl-mapper-tokenizer.js.map